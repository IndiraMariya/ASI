{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv(\"../../data/F10.7.csv\")  # Replace \"your_data.csv\" with the path to your data file\n",
    "\n",
    "# Preprocess the data\n",
    "X = data[['Julian day', 'Carringtonrotation', 'Observed Flux', 'Adjusted Flux', 'URSI Flux']].values\n",
    "y = data['Adjusted Flux'].values  # Adjusted Flux will be our target variable\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data for CNN input (assuming 1D convolution)\n",
    "X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "518/518 [==============================] - 1s 1ms/step - loss: 2044.8704 - val_loss: 862.5042\n",
      "Epoch 2/10\n",
      "518/518 [==============================] - 1s 1ms/step - loss: 589.2459 - val_loss: 63.3954\n",
      "Epoch 3/10\n",
      "518/518 [==============================] - 1s 1ms/step - loss: 230.7088 - val_loss: 26.2242\n",
      "Epoch 4/10\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 216.3708 - val_loss: 7.8246\n",
      "Epoch 5/10\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 210.0078 - val_loss: 8.9940\n",
      "Epoch 6/10\n",
      "518/518 [==============================] - 1s 2ms/step - loss: 184.7605 - val_loss: 2.7500\n",
      "Epoch 7/10\n",
      "518/518 [==============================] - 1s 1ms/step - loss: 180.4444 - val_loss: 19.7087\n",
      "Epoch 8/10\n",
      "518/518 [==============================] - 1s 1ms/step - loss: 177.5464 - val_loss: 10.5826\n",
      "Epoch 9/10\n",
      "518/518 [==============================] - 1s 1ms/step - loss: 172.7446 - val_loss: 15.5612\n",
      "Epoch 10/10\n",
      "518/518 [==============================] - 1s 1ms/step - loss: 188.7216 - val_loss: 1.7480\n",
      "130/130 [==============================] - 0s 460us/step - loss: 1.7480\n",
      "Test Loss: 1.7479850053787231\n"
     ]
    }
   ],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2]), padding='same'),\n",
    "    MaxPooling1D(pool_size=2),\n",
    "    Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
    "    # MaxPooling1D(pool_size=2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1)  # Output layer with one neuron for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(), loss='mse')  # Using Mean Squared Error as loss function\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "Predicted Adjusted Flux for Future Time: [[123.37208]]\n"
     ]
    }
   ],
   "source": [
    "# Define the future data point\n",
    "next_julian_day = 2453309.354\n",
    "next_carrington_rotation = 2022.656\n",
    "next_observed_flux = 137.5\n",
    "next_adjusted_flux = 135.7\n",
    "next_ursi_flux = 121.5\n",
    "\n",
    "# Predict future values\n",
    "future_data = np.array([[next_julian_day, next_carrington_rotation, next_observed_flux, next_adjusted_flux, next_ursi_flux]])\n",
    "future_data_scaled = scaler.transform(future_data)\n",
    "future_data_reshaped = future_data_scaled.reshape((future_data_scaled.shape[0], future_data_scaled.shape[1], 1))\n",
    "future_prediction = model.predict(future_data_reshaped)\n",
    "print(\"Predicted Adjusted Flux for Future Time:\", future_prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "asi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
